{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting to explore daily train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN NUMBER 15, 0.028666666666666668\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26122/1909280718.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      trainNumber  departureDate     HKI     PSL     KÄP     OLK     PMK  \\\n",
      "0               1             10  281.78  281.78  281.78  281.78  281.73   \n",
      "1               2             10  281.78  281.78  281.78  281.78  281.73   \n",
      "2               3             10  281.78  281.78  281.78  281.78  281.73   \n",
      "3               4             10  281.78  281.78  281.78  281.78  281.73   \n",
      "4               5             10  281.78  281.78  281.78  281.78  281.73   \n",
      "...           ...            ...     ...     ...     ...     ...     ...   \n",
      "8995         8669             11  273.90  273.90  273.90  273.90  273.73   \n",
      "8996         8670             11  273.90  273.90  273.90  273.90  273.73   \n",
      "8997         8671             11  273.90  273.90  273.90  273.90  273.73   \n",
      "8998         8673             11  273.90  273.90  273.90  273.90  273.73   \n",
      "8999         8674             11  273.90  273.90  273.90  273.90  273.73   \n",
      "\n",
      "          ML     TNA     PLA  ...  TPV  ILO  VRM  MYL   HA  ILR  HNK  KSK  \\\n",
      "0     281.73  281.73  281.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     281.73  281.73  281.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     281.73  281.73  281.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     281.73  281.73  281.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     281.73  281.73  281.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...      ...     ...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "8995  273.73  273.73  273.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8996  273.73  273.73  273.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8997  273.73  273.73  273.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8998  273.73  273.73  273.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8999  273.73  273.73  273.73  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      NÄR  POR  \n",
      "0     0.0  0.0  \n",
      "1     0.0  0.0  \n",
      "2     0.0  0.0  \n",
      "3     0.0  0.0  \n",
      "4     0.0  0.0  \n",
      "...   ...  ...  \n",
      "8995  0.0  0.0  \n",
      "8996  0.0  0.0  \n",
      "8997  0.0  0.0  \n",
      "8998  0.0  0.0  \n",
      "8999  0.0  0.0  \n",
      "\n",
      "[9000 rows x 504 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "8995    1\n",
      "8996    1\n",
      "8997    0\n",
      "8998    1\n",
      "8999    1\n",
      "Name: total_late, Length: 9000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Hack for using import with relative path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from fetchTrainData import fetch_train_data\n",
    "from fetchWeatherData import fetch_weather_data, save_weather_data, open_weather_data\n",
    "\n",
    "weather_data = {}\n",
    "\n",
    "def get_weather(stop_):\n",
    "    tag = stop_['station.shortCode']\n",
    "    if type(tag) == str:\n",
    "        lat = stop_['station.location'][0]\n",
    "        lon = stop_['station.location'][1]\n",
    "        if tag not in weather_data:\n",
    "            print(\"FETCHING DATA FOR: \" + tag, end = \"\\r\")\n",
    "            weather_data[tag] = fetch_weather_data(unix_time, lat, lon)['list'][0]['main']['temp']\n",
    "\n",
    "            \n",
    "def extract_time_tables(train_stops_):\n",
    "    print(\"TRAIN NUMBER \" + str(train_stops_.name) + \", \" + str(float(train_stops_.name) / number_of_trains), end = \"\\r\")\n",
    "    train_stops = pd.json_normalize(train_stops_)\n",
    "    to_return = train_stops['differenceInMinutes'].sum()\n",
    "    train_stops = train_stops.drop(['differenceInMinutes'], axis=1)\n",
    "\n",
    "    train_stops.apply(get_weather, axis=1)\n",
    "\n",
    "    for stop in train_stops['station.shortCode'].unique():\n",
    "        if type(stop) == str:\n",
    "            if stop not in df.columns:\n",
    "                df[stop] = np.nan\n",
    "\n",
    "            df[stop][train_stops_.name] = weather_data[stop]\n",
    "        \n",
    "    \n",
    "    return to_return\n",
    "\n",
    "\n",
    "loops = 12 # How many months data we want in the dataframe, apparently we can't get over 12 months data\n",
    "number_of_trains = 750 # How many trains to fetch per month. Seems to be softlocked at about 1000, 500 is safe\n",
    "all_data_frames = []\n",
    "all_late_amounts = []\n",
    "\n",
    "\n",
    "for i in range(loops):\n",
    "    date = datetime.date.today() - relativedelta(months = i)\n",
    "    unix_time = time.mktime(date.timetuple())\n",
    "    print(\"LOOP \" + str(i) + \", DATE: \" + str(date))\n",
    "\n",
    "    q = (\n",
    "        \"\"\" \n",
    "        {\n",
    "        \"\"\"\n",
    "          f'  trainsByDepartureDate(departureDate: \\\"{date}\\\",'\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "          f'  take: {number_of_trains},'\n",
    "        \"\"\"\n",
    "            where: {\n",
    "                and: [\n",
    "                    {or: [{deleted: {unequals: null}}, \n",
    "                    {deleted: {equals: false}}]}, \n",
    "                    {cancelled: {equals: false}}, \n",
    "                    {operator: {shortCode: {equals: \"vr\"}}}\n",
    "                    ]  \n",
    "            }\n",
    "          ) \n",
    "          {\n",
    "            trainNumber\n",
    "            departureDate\n",
    "            timeTableRows {\n",
    "            differenceInMinutes\n",
    "              station {\n",
    "                shortCode\n",
    "                location\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    result = fetch_train_data(q)\n",
    "    recs = result['data']['trainsByDepartureDate']\n",
    "\n",
    "    df = pd.json_normalize(recs)\n",
    "    all_stops = pd.json_normalize(df['timeTableRows'])\n",
    "    df = df.drop(['timeTableRows'], axis=1)\n",
    "\n",
    "    weather_data = open_weather_data(date)\n",
    "    how_much_late = all_stops.apply(extract_time_tables, axis=1)\n",
    "    save_weather_data(date, weather_data)\n",
    "    \n",
    "    df['departureDate'] = date.month\n",
    "    \n",
    "    all_data_frames.append(df)\n",
    "    all_late_amounts.append(how_much_late)\n",
    "    \n",
    "combined_train_data = pd.concat(all_data_frames).fillna(0).reset_index().drop(['index'], axis=1)\n",
    "combined_late_amounts = pd.concat(all_late_amounts).fillna(0).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "combined_late_amounts.rename(columns={0: \"total_late\"}, inplace=True)\n",
    "combined_late_amounts = combined_late_amounts[\"total_late\"].apply(lambda x: int(x > 4))\n",
    "\n",
    "print(combined_train_data)\n",
    "print(combined_late_amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST SCORE: 0.7333333333333333\n",
      "NEW BEST SCORE: 0.7488888888888889\n",
      "NEW BEST SCORE: 0.7544444444444445\n",
      "0.7383333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, model_selection, pipeline, preprocessing\n",
    "\n",
    "best_score = 0\n",
    "best_reg = linear_model.SGDClassifier(max_iter=1000)\n",
    "\n",
    "for i in range(100):\n",
    "    print(i, end = \"\\r\")\n",
    "    training_data, test_data, train_target, test_target = model_selection.train_test_split(combined_train_data, combined_late_amounts, train_size=0.8)\n",
    "    train_target = np.ravel(train_target)\n",
    "    test_target = np.ravel(test_target)\n",
    "\n",
    "    reg = linear_model.SGDClassifier(max_iter=1000)\n",
    "    reg.fit(training_data, train_target)\n",
    "    reg_score = reg.score(test_data, test_target)\n",
    "    if reg_score > best_score:\n",
    "        best_score = reg_score\n",
    "        best_reg = reg\n",
    "        print(\"NEW BEST SCORE: \" + str(best_score))\n",
    "        \n",
    "print(best_reg.score(test_data, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('HKI', 'Helsinki'), ('PSL', 'Pasila'), ('TKL', 'Tikkurila'), ('KE', 'Kerava'), ('JNS', 'Joensuu'), ('TPE', 'Tampere'), ('TKU', 'Turku'), ('HL', 'Hämeenlinna'), ('OL', 'Oulu'), ('SK', 'Seinäjoki'), ('JY', 'Jyväskylä'), ('KV', 'Kouvola')]\n",
      "[True, True, True, True, True, True, True, True, True, True, False, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26122/11428761.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[stop] = np.nan\n",
      "/tmp/ipykernel_26122/11428761.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[station] = 0.0\n",
      "/home/otters/git/VRbad.io/venv/lib/python3.8/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def extract_time_tables_station(train_stops_):\n",
    "    train_stops = pd.json_normalize(train_stops_)\n",
    "\n",
    "    train_stops.apply(get_weather, axis=1)\n",
    "\n",
    "    for stop in train_stops['station.shortCode'].unique():\n",
    "        if type(stop) == str:\n",
    "            if stop not in df.columns:\n",
    "                df[stop] = np.nan\n",
    "\n",
    "            df[stop][train_stops_.name] = weather_data[stop]\n",
    "            \n",
    "# List here stations that are checked, and possible tweeted about\n",
    "stations_to_check = [('HKI', 'Helsinki'), ('PSL', 'Pasila'), ('TKL', 'Tikkurila'), ('KE', 'Kerava'), \n",
    "                     ('JNS', 'Joensuu'), ('TPE', 'Tampere'), ('TKU', 'Turku'), ('HL', 'Hämeenlinna'), \n",
    "                     ('OL', 'Oulu'), ('SK', 'Seinäjoki'), ('JY', 'Jyväskylä'), ('KV', 'Kouvola')]\n",
    "results = []\n",
    "\n",
    "\n",
    "for station in stations_to_check:\n",
    "    date = datetime.date.today()\n",
    "    unix_time = time.mktime(date.timetuple())\n",
    "    \n",
    "    q = (\n",
    "        \"\"\" \n",
    "        {\n",
    "        \"\"\"\n",
    "          f'  trainsByStationAndQuantity(station: \"{station[0]}\",'\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "          f'  take: {200},'\n",
    "        \"\"\"\n",
    "            where: {\n",
    "                and: [\n",
    "                    {or: [{deleted: {unequals: null}}, \n",
    "                    {deleted: {equals: false}}]}, \n",
    "                    {cancelled: {equals: false}}, \n",
    "                    {operator: {shortCode: {equals: \"vr\"}}}\n",
    "                    ]  \n",
    "            }\n",
    "          ) \n",
    "          {\n",
    "            trainNumber\n",
    "            departureDate\n",
    "            timeTableRows {\n",
    "              station {\n",
    "                shortCode\n",
    "                location\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "        )\n",
    "    \n",
    "    result = fetch_train_data(q)\n",
    "    recs = result['data']['trainsByStationAndQuantity']\n",
    "\n",
    "    df = pd.json_normalize(recs)\n",
    "    all_stops = pd.json_normalize(df['timeTableRows'])\n",
    "    df = df.drop(['timeTableRows'], axis=1)\n",
    "    \n",
    "    weather_data = open_weather_data(date)\n",
    "    all_stops.apply(extract_time_tables_station, axis=1)\n",
    "    save_weather_data(date, weather_data)\n",
    "    \n",
    "    df['departureDate'] = date.month\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    for station in best_reg.feature_names_in_:\n",
    "        if station not in df.columns:\n",
    "            df[station] = 0.0\n",
    "            \n",
    "    for station in df.columns:\n",
    "        if station not in best_reg.feature_names_in_:\n",
    "            df.drop([station], inplace=True, axis=1)\n",
    "    \n",
    "    how_many_late = 0\n",
    "    for prediction in best_reg.predict(df):\n",
    "        if prediction == 1:\n",
    "            how_many_late = how_many_late + 1\n",
    "            \n",
    "    if how_many_late >= df.shape[0] / 2:\n",
    "        results.append(True)\n",
    "    else:\n",
    "        results.append(False)\n",
    "        \n",
    "print(stations_to_check)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5d966f8ef4220096744806d83432b9a228778896d08cdcbc2e266632b99e2da"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
